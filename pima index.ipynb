{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "The Pima are a group of Native Americans living in Arizona. A genetic predisposition allowed this group to survive normally to a diet poor of carbohydrates for years. In the recent years, because of a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, made them develop the highest prevalence of type 2 diabetes and for this reason they have been subject of many studies.\n",
    "\n",
    "### Dataset<br>\n",
    "The dataset includes data from 768 women with 8 characteristics, in particular:\n",
    "<br>\n",
    " 1. Number of times pregnant\n",
    " 2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    " 3. Diastolic blood pressure (mm Hg)\n",
    " 4. Triceps skin fold thickness (mm)\n",
    " 5. 2-Hour serum insulin (mu U/ml)\n",
    " 6. Body mass index (weight in kg/(height in m)^2)\n",
    " 7. Diabetes pedigree function\n",
    " 8. Age (years)<br>\n",
    "The last column of the dataset indicates if the person has been diagnosed with diabetes (1) or not (0) \n",
    "### Source-\n",
    "The original dataset is available at UCI Machine Learning Repository and can be downloaded from this address: http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem Statement\n",
    "The type of dataset and problem is a classic supervised binary classification. Given a number of elements all with certain characteristics (features), we want to build a machine learning model to identify people affected by type 2 diabetes.\n",
    "\n",
    "To solve the problem we will have to analyse the data, do any required transformation and normalisation, apply a machine learning algorithm, train a model, check the performance of the trained model and iterate with other algorithms until we find the most performant for our type of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load ,Preprocess and Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/pankaj/projects/diabetes pima index/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data correlation matrix\n",
    "The correlation matrix is an important tool to understand the correlation between the different characteristics. The values range from -1 to 1 and the closer a value is to 1 the bettere correlation there is between two characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
       "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
       "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
       "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
       "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
       "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
       "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
       "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
       "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
       "Glucose                   0.331357  0.221071                  0.137337   \n",
       "BloodPressure             0.088933  0.281805                  0.041265   \n",
       "SkinThickness             0.436783  0.392573                  0.183928   \n",
       "Insulin                   1.000000  0.197859                  0.185071   \n",
       "BMI                       0.197859  1.000000                  0.140647   \n",
       "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
       "Age                      -0.042163  0.036242                  0.033561   \n",
       "Outcome                   0.130548  0.292695                  0.173844   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.544341  0.221898  \n",
       "Glucose                   0.263514  0.466581  \n",
       "BloodPressure             0.239528  0.065068  \n",
       "SkinThickness            -0.113970  0.074752  \n",
       "Insulin                  -0.042163  0.130548  \n",
       "BMI                       0.036242  0.292695  \n",
       "DiabetesPedigreeFunction  0.033561  0.173844  \n",
       "Age                       1.000000  0.238356  \n",
       "Outcome                   0.238356  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not a doctor and I don't have any knowledge of medicine, but from the data I can guess that the greater the age or the BMI of a patient is, the greater probabilities are the patient can develop type 2 diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the dataset\n",
    "Visualising the data is an important step of the data analysis. With a graphical visualisation of the data we have a better understanding of the various features values distribution: for example we can understand what's the average age of the people or the average BMI etc...\n",
    "\n",
    "We could of course limit our inspection to the table visualisation, but we could miss important things that may affect our model precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c289fbc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing I notice in the dataset (and that wasn't obvious at the beginning) is the fact that some people have null (zero) values for some of the features: it's not quite possible to have 0 as BMI or for the blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data cleaning and transformation\n",
    "We have noticed from the previous analysis that some patients have missing data for some of the features. Machine learning algorithms don't work very well when the data is missing so we have to find a solution to \"clean\" the data we have.\n",
    "\n",
    "The easiest option could be to eliminate all those patients with null/zero values, but in this way we would eliminate a lot of important data.\n",
    "\n",
    "Another option is to calculate the median value for a specific column and substitute that value everywhere (in the same column) we have zero or null. Let's see how to apply this second method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value for BMI\n",
    "median_bmi = data['BMI'].median()\n",
    "# Substitute it in the BMI column of the\n",
    "# dataset where values are 0\n",
    "data['BMI'] = data['BMI'].replace(to_replace=0, value=median_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value for BloodP\n",
    "median_bloodp = data['BloodPressure'].median()\n",
    "# Substitute it in the BloodP column of the\n",
    "# dataset where values are 0\n",
    "data['BloodPressure'] = data['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value for PlGlcConc\n",
    "median_plglcconc = data['Glucose'].median()\n",
    "# Substitute it in the PlGlcConc column of the\n",
    "# dataset where values are 0\n",
    "data['Glucose'] = data['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value for SkinThick\n",
    "median_skinthick = data['SkinThickness'].median()\n",
    "# Substitute it in the SkinThick column of the\n",
    "# dataset where values are 0\n",
    "data['SkinThickness'] = data['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value for TwoHourSerIns\n",
    "median_twohourserins = data['Insulin'].median()\n",
    "# Substitute it in the TwoHourSerIns column of the\n",
    "# dataset where values are 0\n",
    "data['Insulin'] = data['Insulin'].replace(\n",
    "    to_replace=0, value=median_twohourserins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't transformed all the columns, because for some values can make sense to be zero (like \"Number of times pregnant\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.values\n",
    "y=x[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print x.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select and train model\n",
    "It's not possible to know in advance which algorithm will work better with our dataset. We need to compare a few and select the one with the \"best score\".\n",
    "## Comparing multiple algorithms\n",
    "To compare multiple algorithms with the same dataset, there is a very nice utility in sklearn called model_selection. We create a list of algorithms and then we score them using the same comparison method. At the end we pick the one with the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the algorithms we want to test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the slearn utility to compare algorithms\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an array with all the algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('LSVC', LinearSVC()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('DTR', DecisionTreeRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the configuration to run the test\n",
    "seed = 7\n",
    "results = []\n",
    "names = []\n",
    "X = x_train\n",
    "Y = y_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.758911 (0.034867)\n",
      "KNN: 0.726415 (0.048770)\n",
      "NB: 0.739450 (0.062140)\n",
      "SVC: 0.653014 (0.050337)\n",
      "LSVC: 0.587203 (0.144219)\n",
      "RFC: 0.744183 (0.044644)\n",
      "DTR: 0.711660 (0.040236)\n"
     ]
    }
   ],
   "source": [
    "# Every algorithm is tested and results are\n",
    "# collected and printed\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(X.shape[0], n_folds=10,shuffle=False)\n",
    "    cv_results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (\n",
    "        name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c2102b0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like that using this comparison method, the most performant algorithm is SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best parameters for SVC\n",
    "The default parameters for an algorithm are rarely the best ones for our dataset. Using sklearn we can easily build a parameters grid and try all the possible combinations. At the end we inspect the best_estimator_ property and get the best ones for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear'], 'C': [1.0], 'shrinking': [True], 'gamma': ['auto'], 'coef0': [0.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1.0],\n",
    "    'kernel': ['linear'],\n",
    "    'shrinking': [True],\n",
    "    'gamma': ['auto'],\n",
    "    'coef0': [0.0]\n",
    "}\n",
    "\n",
    "model_svc = SVC()\n",
    "\n",
    "grid = GridSearchCV(model_svc, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76058631921824105"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Increase The Accuracy Of Models Using Ensemble methods\n",
    "It can take time to find well performing machine learning algorithms for your dataset. This is because of the trial and error nature of applied machine learning.\n",
    "\n",
    "Once we have a shortlist of accurate models, we can use algorithm tuning to get the most from each algorithm.\n",
    "\n",
    "Another approach that we can use to increase accuracy on your dataset is to combine the predictions of multiple different models together.\n",
    "\n",
    "This is called an ensemble prediction.\n",
    "\n",
    "Combine Model Predictions Into Ensemble Predictions\n",
    "The three most popular methods for combining the predictions from different models are:\n",
    "\n",
    "1. Bagging. Building multiple models (typically of the same type) from different subsamples of the training dataset.\n",
    "2. Boosting. Building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the chain.\n",
    "3. Stacking. Building multiple models (typically of differing types) and supervisor model that learns how to best combine the predictions of the primary models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Stacked Generalization Algorithm\n",
    "Stacked Generalization or stacking is an ensemble algorithm where a new model is trained to combine the predictions from two or more models already trained or your dataset.\n",
    "\n",
    "The predictions from the existing models or submodels are combined using a new model, and as such stacking is often referred to as blending, as the predictions from sub-models are blended together.\n",
    "\n",
    "It is typical to use a simple linear method to combine the predictions for submodels such as simple averaging or voting, to a weighted sum using linear regression or logistic regression.\n",
    "\n",
    "Models that have their predictions combined must have skill on the problem, but do not need to be the best possible models. This means that you do not need to tune the submodels intently, as long as the model shows some advantage over a baseline prediction.\n",
    "\n",
    "It is important that sub-models produce different predictions, so-called uncorrelated predictions. Stacking works best when the predictions that are combined are all skillful, but skillful in different ways. This may be achieved by using algorithms that use very different internal representations (trees compared to instances) and/or models trained on different representations or projections of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking model\n",
    "We are going to use two models as submodels for stacking and a logistic regression model as the aggregator model.\n",
    "\n",
    "This part is divided into 3 sections:\n",
    "\n",
    "1. Sub-model #1: SVM.\n",
    "2. Sub-model #2: Random Forest.\n",
    "3. Aggregator Model: Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-model #1: SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf=svm.SVC();\n",
    "clf.fit(x_train,y_train)\n",
    "pred1=clf.predict(x_train)\n",
    "y_pred1=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_test, y_pred1)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-model #2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753246753247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3=RandomForestClassifier()\n",
    "clf3.fit(x_train,y_train)\n",
    "pred3=clf.predict(x_train)\n",
    "y_pred3=clf3.predict(x_test)\n",
    "acc=accuracy_score(y_test,y_pred3)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregator Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753246753247\n"
     ]
    }
   ],
   "source": [
    "pred=np.column_stack((pred1,pred3))\n",
    "y_pred=np.column_stack((y_pred1,y_pred3))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2=LogisticRegression()\n",
    "clf2.fit(pred,y_train)\n",
    "y_pred2=clf2.predict(y_pred)\n",
    "acc=accuracy_score(y_test,y_pred2)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "This section lists extensions to this tutorial that we can explore.\n",
    "\n",
    "- <b>Tune Algorithms</b>. The algorithms used for the submodels and the aggregate model in this tutorial can be further tuned.We can explore ore alternate configurations and see if it lifts performance.\n",
    "- <b>Prediction Correlations</b>. Stacking works better if the predictions of submodels are weakly correlated. Implementing calculations to estimate the correlation between the predictions of submodels increases efficiency.\n",
    "- <b>Different Sub-models</b>. We can also implement more and different sub-models to be combined using the stacking procedure.\n",
    "- <b>Different Aggregating Model</b>.We can also experiment with simpler models (like averaging and voting) and more complex aggregation models .\n",
    "- <b>More Datasets</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
